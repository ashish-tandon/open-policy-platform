=== Thu Aug 14 10:47:22 EDT 2025 - pulling updates ===
HEAD is now at f9bc4c37 chore(db): add scrapers engine/url alongside app DB for future writes
=== rebuild and up core ===
#1 [internal] load local bake definitions
#1 reading from stdin 1.23kB done
#1 DONE 0.0s

#2 [api internal] load build definition from Dockerfile
#2 transferring dockerfile: 1.17kB done
#2 DONE 0.0s

#3 [web internal] load build definition from Dockerfile
#3 transferring dockerfile: 343B done
#3 DONE 0.0s

#4 [auth] library/python:pull token for registry-1.docker.io
#4 DONE 0.0s

#5 [auth] library/node:pull token for registry-1.docker.io
#5 DONE 0.0s

#6 [scraper-runner internal] load metadata for docker.io/library/python:3.11-slim
#6 DONE 0.4s

#7 [web internal] load metadata for docker.io/library/node:20-alpine
#7 DONE 0.4s

#8 [scraper-runner internal] load .dockerignore
#8 transferring context: 2B done
#8 DONE 0.0s

#9 [web internal] load .dockerignore
#9 transferring context: 2B done
#9 DONE 0.0s

#10 [scraper-runner 1/8] FROM docker.io/library/python:3.11-slim@sha256:9e885f8239c31f8429448f933638dd13037c9119e2a362aeebdd37ec3bee7c85
#10 resolve docker.io/library/python:3.11-slim@sha256:9e885f8239c31f8429448f933638dd13037c9119e2a362aeebdd37ec3bee7c85 0.0s done
#10 DONE 0.0s

#11 [scraper-runner internal] load build context
#11 ...

#12 [web 1/5] FROM docker.io/library/node:20-alpine@sha256:df02558528d3d3d0d621f112e232611aecfee7cbc654f6b375765f72bb262799
#12 resolve docker.io/library/node:20-alpine@sha256:df02558528d3d3d0d621f112e232611aecfee7cbc654f6b375765f72bb262799 0.0s done
#12 DONE 0.0s

#13 [web internal] load build context
#13 transferring context: 7.79kB 0.0s done
#13 DONE 0.1s

#14 [web 2/5] WORKDIR /app
#14 CACHED

#15 [web 3/5] COPY package*.json ./
#15 CACHED

#16 [web 4/5] RUN npm ci --no-audit --no-fund
#16 CACHED

#17 [web 5/5] COPY . .
#17 CACHED

#11 [scraper-runner internal] load build context
#11 ...

#18 [web] exporting to oci image format
#18 exporting layers 0.0s done
#18 exporting manifest sha256:5f08d840e3eb359f93cb52ea3353cd979ed307ffee711d0e748b1da5fa34cd93 done
#18 exporting config sha256:dbd6609a30ac36991a77c28efc5e1a513939911ee6cedd38e6bea449a58e1568 done
#18 sending tarball 1.9s done
#18 DONE 1.9s

#19 importing to docker
#19 DONE 0.0s

#11 [scraper-runner internal] load build context
#11 ...

#20 [web] resolving provenance for metadata file
#20 DONE 0.0s

#11 [scraper-runner internal] load build context
#11 transferring context: 2.89MB 3.4s done
#11 DONE 3.7s

#21 [scraper-runner 4/8] COPY requirements.txt .
#21 CACHED

#22 [scraper-runner 2/8] WORKDIR /app
#22 CACHED

#23 [scraper-runner 3/8] RUN apt-get update && apt-get install -y     postgresql-client     curl     wget     build-essential     gcc     python3-dev     && rm -rf /var/lib/apt/lists/*
#23 CACHED

#24 [scraper-runner 5/8] RUN pip install --no-cache-dir -r requirements.txt
#24 CACHED

#25 [scraper-runner 6/8] COPY . .
#25 DONE 9.2s

#26 [api 7/8] RUN mkdir -p logs data migrations
#26 DONE 0.2s

#27 [scraper-runner 8/8] RUN useradd --create-home --shell /bin/bash openpolicy &&     chown -R openpolicy:openpolicy /app
#27 DONE 24.3s

#28 [api] exporting to oci image format
#28 exporting layers
#28 exporting layers 8.3s done
#28 exporting manifest sha256:a79892f1eedccb4925af9dbe398847cfefa6634a58c50e9e7c20f423feaafe16 done
#28 exporting config sha256:2a1a992829f832040883f5536dbb821f0c743bc2cea02e0c4b3eb3e7a81d2dec done
#28 sending tarball
#28 ...

#29 [scraper-runner] exporting to oci image format
#29 exporting layers 8.3s done
#29 exporting manifest sha256:a79892f1eedccb4925af9dbe398847cfefa6634a58c50e9e7c20f423feaafe16 done
#29 exporting config sha256:2a1a992829f832040883f5536dbb821f0c743bc2cea02e0c4b3eb3e7a81d2dec done
#29 ...

#30 importing to docker
#30 DONE 0.0s

#29 [scraper-runner] exporting to oci image format
#29 sending tarball 12.4s done
#29 DONE 20.7s

#28 [api] exporting to oci image format
#28 sending tarball 12.4s done
#28 DONE 20.7s

#31 importing to docker
#31 DONE 0.0s

#32 [api] resolving provenance for metadata file
#32 DONE 0.0s

#33 [scraper-runner] resolving provenance for metadata file
#33 DONE 0.0s
=== wait for API ===
API healthy
=== smoke test ===
API OK: http://localhost:8000
API detailed OK
Web OK: http://localhost:5173
DB OK: localhost:5432
=== backend tests ===
=== done ===
