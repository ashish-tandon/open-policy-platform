# Status - 2025-08-14

- Infra: single compose, healthchecks, scraper-runner; ports standardized.
- Backend: uvicorn on 8000; DB health via SQLAlchemy; scrapers read reports/logs from configured dirs.
- UI: admin/public scrapers pages (list, categories, run-by-category).
- CI/CD: tests + web build + port validation + compose smoke; tag-based image build/push; dispatch to deploy repo; k8s deploy on dispatch.
- K8s: API Deployment/Service/Ingress with probes.
- Docs: service standards, data flow, execution plan, deploy triggers.

## Feature matrix
- Data collection (scrapers)
  - Federal (openparliament): integrated pathing; runner staging to writable work dir; outputs synced to `/app/scrapers-data` — PARTIAL (framework execution verified; dataset import pending)
  - Provincial/municipal (scrapers-ca): inventory wired; execution staging in place — PARTIAL (table presence/ingest pending)
  - Scheduling: daily/weekly/monthly/continuous via background runner — DONE
  - Monitoring: runner logs and API monitoring endpoints — DONE
- Databases
  - Logical DBs: `openpolicy_app`, `openpolicy_scrapers`, `openpolicy_auth` — DONE (auto-created)
  - Schemas: minimal app/scrapers schemas — PARTIAL (sample seeds available locally; real schema import pending)
  - Seeding: helper script `scripts/seed_db.sh` — DONE (local-only seeds; repo ignores `.sql`)
- API
  - Health, metrics, dashboard — DONE
  - Entities (representatives, bills, committees, votes, events) — DONE (queries run if tables exist)
  - Scraper monitoring (summary, runs, attempts, DB status) — DONE (tables required)
  - Policies endpoints — PRESENT (requires real data population)
- Web UI
  - Dev server wiring (Vite): DONE
  - Scraper pages: PRESENT
  - Entities browsing: TODO (basic list/search views)
  - Admin dashboards (metrics/logs): PARTIAL

## Gaps and blockers
- Real data ingestion
  - OpenParliament dump import and mapping to `openpolicy_app` tables
  - `scraper_runs`/`scraper_results` population from runner executions
- Test coverage
  - Add API smoke tests in CI; add Entities endpoint verification after seed
- Observability
  - Persist runner logs to a mapped volume; add Grafana dashboards for scrapers
- Security
  - Harden `ALLOWED_HOSTS`/`ALLOWED_ORIGINS` for prod; strong `SECRET_KEY` policy enforced

## TODO checklist
- Data ingestion
  - [ ] Write import script(s) for OpenParliament datasets into `openpolicy_app`
  - [ ] Add ETL from runner outputs into `scraper_runs`/`scraper_results`
  - [ ] Define schema migrations for stable app tables (alembic)
- Runner and scrapers
  - [ ] Verify each category runs end-to-end with staging work dir
  - [ ] Map runner logs to host and add retention
  - [ ] Add configurable max concurrency and backoff
- API
  - [ ] Entities: add pagination metadata (`total`) via COUNT
  - [ ] Add search facets for bills/committees
  - [ ] Add admin endpoint to trigger/import ETL
- Web UI
  - [ ] Implement Entities list/detail pages with search and pagination
  - [ ] Admin: health dashboards, scraper runs/attempts views, log viewer
- CI/CD
  - [ ] Run `scripts/smoke.sh` on PRs against compose
  - [ ] Export OpenAPI in CI and publish artifact
- Docs
  - [ ] Add data model and mapping docs for OpenParliament → `openpolicy_app`
  - [ ] Add runbook for seeding/ingestion and troubleshooting

## How to validate end-to-end
- Bring up stack: `docker compose up -d --build postgres api web redis`
- Seed minimal data locally: `bash scripts/seed_db.sh`
- Start runner: `docker compose up -d scraper-runner`
- Smoke tests: `bash scripts/smoke-test.sh`
- Verify `/app/scrapers-data/...` contains timestamped runs; confirm Entities endpoints return non-empty results after ingestion.
