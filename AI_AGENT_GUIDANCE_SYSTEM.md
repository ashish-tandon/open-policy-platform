# ü§ñ AI Agent Guidance System - OpenPolicy Merge

## üéØ **MISSION CONTROL: KEEPING AI AGENTS ON TRACK**

This document serves as the **SINGLE SOURCE OF TRUTH** for all AI agents working on the OpenPolicy Merge project. It ensures consistency, prevents confusion, and maintains development focus.

---

## üìã **CORE PRINCIPLES**

### **1. PLAN BEFORE EXECUTE**
- ‚úÖ **ALWAYS** review the comprehensive development plan before making changes
- ‚úÖ **ALWAYS** check test coverage requirements before implementing features
- ‚úÖ **ALWAYS** validate against acceptance criteria before proceeding
- ‚úÖ **NEVER** skip planning phase or rush to implementation

### **2. TEST-DRIVEN DEVELOPMENT**
- ‚úÖ **ALWAYS** write tests before implementing features
- ‚úÖ **ALWAYS** ensure 100% test coverage for all components
- ‚úÖ **ALWAYS** verify tests pass before committing code
- ‚úÖ **NEVER** implement features without corresponding tests

### **3. DOCUMENTATION FIRST**
- ‚úÖ **ALWAYS** update documentation when making changes
- ‚úÖ **ALWAYS** maintain clear commit messages
- ‚úÖ **ALWAYS** track progress in development logs
- ‚úÖ **NEVER** make undocumented changes

---

## üó∫Ô∏è **DEVELOPMENT ROADMAP CHECKLIST**

### **CURRENT STATUS: PLANNING PHASE COMPLETE**
- ‚úÖ Comprehensive Architecture Plan
- ‚úÖ Comprehensive Test Plan
- ‚úÖ Comprehensive Script Testing Plan
- ‚úÖ Comprehensive Development Plan

### **NEXT PHASE: IMPLEMENTATION PHASE (Weeks 1-4)**

#### **Week 1: Script Testing Implementation**
```bash
# PRIORITY 1: Migration Script Tests
- [ ] test_migration_script_execution()
- [ ] test_backup_creation_success()
- [ ] test_schema_updates_applied()
- [ ] test_data_migration_complete()
- [ ] test_fresh_data_collection()

# PRIORITY 2: Scraper Script Tests
- [ ] test_scraper_script_execution()
- [ ] test_data_collection_from_source()
- [ ] test_database_insertion_success()
- [ ] test_data_validation_after_insertion()
- [ ] test_error_handling_for_failed_scrapes()

# PRIORITY 3: Deployment Script Tests
- [ ] test_deployment_script_execution()
- [ ] test_service_startup_success()
- [ ] test_database_connection_establishment()
- [ ] test_api_endpoint_availability()
- [ ] test_frontend_loading_success()
```

#### **Week 2: Database & API Testing Enhancement**
```bash
# PRIORITY 1: Enhanced Database Tests
- [ ] test_all_tables_exist()
- [ ] test_all_columns_exist()
- [ ] test_all_constraints_valid()
- [ ] test_all_foreign_keys_valid()
- [ ] test_all_indexes_created()

# PRIORITY 2: Enhanced API Tests
- [ ] test_login_success()
- [ ] test_login_invalid_credentials()
- [ ] test_token_validation()
- [ ] test_password_reset()
- [ ] test_account_creation()

# PRIORITY 3: Integration Tests
- [ ] test_scraper_to_database_flow()
- [ ] test_database_to_api_flow()
- [ ] test_api_to_frontend_flow()
- [ ] test_user_input_validation_flow()
- [ ] test_error_handling_flow()
```

---

## üîç **AI AGENT VALIDATION CHECKLIST**

### **BEFORE STARTING ANY TASK:**
```bash
# 1. Check Current Phase
- [ ] Verify we're in the correct development phase
- [ ] Check if prerequisites are met
- [ ] Validate against development plan

# 2. Review Test Requirements
- [ ] Check test coverage requirements
- [ ] Verify test implementation plan
- [ ] Ensure no test gaps exist

# 3. Validate Scope
- [ ] Confirm task is within current phase scope
- [ ] Check for dependencies
- [ ] Verify acceptance criteria
```

### **DURING TASK EXECUTION:**
```bash
# 1. Follow TDD Approach
- [ ] Write test first
- [ ] Implement feature
- [ ] Verify test passes
- [ ] Update documentation

# 2. Maintain Quality Standards
- [ ] Follow coding standards
- [ ] Ensure error handling
- [ ] Validate data integrity
- [ ] Check performance impact

# 3. Track Progress
- [ ] Update task checklist
- [ ] Document changes
- [ ] Commit with clear messages
- [ ] Update development log
```

### **AFTER TASK COMPLETION:**
```bash
# 1. Validation
- [ ] Run all relevant tests
- [ ] Verify acceptance criteria met
- [ ] Check for regressions
- [ ] Validate documentation

# 2. Integration
- [ ] Test integration with other components
- [ ] Verify data flow integrity
- [ ] Check system stability
- [ ] Validate user experience

# 3. Documentation
- [ ] Update technical documentation
- [ ] Update user documentation
- [ ] Update development log
- [ ] Commit all changes
```

---

## üö® **CONFUSION PREVENTION RULES**

### **1. SINGLE TASK FOCUS**
- ‚úÖ **ALWAYS** work on one task at a time
- ‚úÖ **ALWAYS** complete current task before starting next
- ‚úÖ **ALWAYS** validate current task before proceeding
- ‚úÖ **NEVER** multitask or jump between tasks

### **2. CLEAR TASK DEFINITION**
- ‚úÖ **ALWAYS** define task scope clearly
- ‚úÖ **ALWAYS** specify acceptance criteria
- ‚úÖ **ALWAYS** identify dependencies
- ‚úÖ **NEVER** start undefined tasks

### **3. PROGRESS TRACKING**
- ‚úÖ **ALWAYS** update task status
- ‚úÖ **ALWAYS** document progress
- ‚úÖ **ALWAYS** track completion percentage
- ‚úÖ **NEVER** lose track of progress

### **4. ERROR HANDLING**
- ‚úÖ **ALWAYS** handle errors gracefully
- ‚úÖ **ALWAYS** log error details
- ‚úÖ **ALWAYS** provide recovery options
- ‚úÖ **NEVER** ignore errors or warnings

---

## üìä **DEVELOPMENT METRICS TRACKING**

### **Daily Progress Metrics**
```bash
# Test Implementation Progress
- [ ] Tests implemented today: ___/___
- [ ] Tests passing: ___/___
- [ ] Test coverage: ___%
- [ ] Test failures: ___/___

# Code Quality Metrics
- [ ] Code review completed: Yes/No
- [ ] Documentation updated: Yes/No
- [ ] Linting passed: Yes/No
- [ ] Security scan passed: Yes/No

# Development Progress
- [ ] Tasks completed: ___/___
- [ ] Phase completion: ___%
- [ ] Blockers identified: ___/___
- [ ] Dependencies resolved: ___/___
```

### **Weekly Progress Metrics**
```bash
# Phase Completion
- [ ] Week 1: Script Testing Implementation: ___%
- [ ] Week 2: Database & API Testing: ___%
- [ ] Week 3: Frontend & Security Testing: ___%
- [ ] Week 4: Accessibility & E2E Testing: ___%

# Quality Metrics
- [ ] Test coverage: ___%
- [ ] Code quality score: ___%
- [ ] Documentation completeness: ___%
- [ ] Security compliance: ___%

# Performance Metrics
- [ ] API response time: ___ms
- [ ] Database query time: ___ms
- [ ] Frontend loading time: ___ms
- [ ] System uptime: ___%
```

---

## üîß **TECHNICAL GUIDELINES**

### **Code Standards**
```bash
# Python Standards
- [ ] Follow PEP 8 style guide
- [ ] Use type hints
- [ ] Add docstrings
- [ ] Handle exceptions properly
- [ ] Use meaningful variable names

# JavaScript/TypeScript Standards
- [ ] Follow ESLint rules
- [ ] Use TypeScript types
- [ ] Add JSDoc comments
- [ ] Handle async operations properly
- [ ] Use meaningful function names

# Database Standards
- [ ] Use proper SQL syntax
- [ ] Add indexes for performance
- [ ] Use transactions for data integrity
- [ ] Handle connection pooling
- [ ] Implement proper error handling
```

### **Testing Standards**
```bash
# Test Structure
- [ ] Use descriptive test names
- [ ] Follow AAA pattern (Arrange, Act, Assert)
- [ ] Test one thing per test
- [ ] Use meaningful test data
- [ ] Clean up after tests

# Test Coverage
- [ ] Aim for 100% code coverage
- [ ] Test happy path scenarios
- [ ] Test error scenarios
- [ ] Test edge cases
- [ ] Test integration points
```

### **Documentation Standards**
```bash
# Code Documentation
- [ ] Add inline comments for complex logic
- [ ] Document function parameters and return values
- [ ] Explain business logic
- [ ] Document error handling
- [ ] Keep comments up to date

# API Documentation
- [ ] Document all endpoints
- [ ] Provide request/response examples
- [ ] Document error codes
- [ ] Explain authentication
- [ ] Keep documentation current
```

---

## üöÄ **IMPLEMENTATION CHECKLIST**

### **Current Task: Week 1 - Script Testing Implementation**

#### **Day 1-2: Migration Script Tests**
```bash
# Task 1: test_migration_script_execution()
- [ ] Create test file: backend/tests/scripts/test_migration_script.py
- [ ] Implement test setup
- [ ] Mock database operations
- [ ] Test script execution
- [ ] Verify success criteria
- [ ] Add to test suite
- [ ] Update documentation

# Task 2: test_backup_creation_success()
- [ ] Implement backup test
- [ ] Mock file system operations
- [ ] Test backup file creation
- [ ] Verify backup integrity
- [ ] Add error handling tests
- [ ] Update test coverage

# Task 3: test_schema_updates_applied()
- [ ] Implement schema test
- [ ] Mock database schema operations
- [ ] Test column additions
- [ ] Test constraint updates
- [ ] Verify schema integrity
- [ ] Add rollback tests

# Task 4: test_data_migration_complete()
- [ ] Implement data migration test
- [ ] Mock data operations
- [ ] Test data preservation
- [ ] Test data transformation
- [ ] Verify data integrity
- [ ] Add performance tests

# Task 5: test_fresh_data_collection()
- [ ] Implement fresh data test
- [ ] Mock scraper operations
- [ ] Test data collection
- [ ] Test data storage
- [ ] Verify data freshness
- [ ] Add validation tests
```

#### **Day 3-4: Scraper Script Tests**
```bash
# Task 6: test_scraper_script_execution()
- [ ] Create test file: backend/tests/scripts/test_scraper_scripts.py
- [ ] Implement scraper execution test
- [ ] Mock HTTP requests
- [ ] Test scraper initialization
- [ ] Test scraper completion
- [ ] Add error handling tests

# Task 7: test_data_collection_from_source()
- [ ] Implement data collection test
- [ ] Mock external APIs
- [ ] Test data parsing
- [ ] Test data validation
- [ ] Verify data completeness
- [ ] Add performance tests

# Task 8: test_database_insertion_success()
- [ ] Implement database insertion test
- [ ] Mock database operations
- [ ] Test data insertion
- [ ] Test data retrieval
- [ ] Verify data consistency
- [ ] Add transaction tests

# Task 9: test_data_validation_after_insertion()
- [ ] Implement data validation test
- [ ] Test data format validation
- [ ] Test data type validation
- [ ] Test constraint validation
- [ ] Verify data quality
- [ ] Add cleanup tests

# Task 10: test_error_handling_for_failed_scrapes()
- [ ] Implement error handling test
- [ ] Mock network failures
- [ ] Test graceful degradation
- [ ] Test error logging
- [ ] Test recovery mechanisms
- [ ] Add retry tests
```

#### **Day 5-7: Deployment Script Tests**
```bash
# Task 11: test_deployment_script_execution()
- [ ] Create test file: backend/tests/scripts/test_deployment_scripts.py
- [ ] Implement deployment test
- [ ] Mock system operations
- [ ] Test script execution
- [ ] Test environment setup
- [ ] Add rollback tests

# Task 12: test_service_startup_success()
- [ ] Implement service startup test
- [ ] Mock service operations
- [ ] Test service initialization
- [ ] Test service health checks
- [ ] Verify service availability
- [ ] Add failure tests

# Task 13: test_database_connection_establishment()
- [ ] Implement database connection test
- [ ] Mock database connections
- [ ] Test connection establishment
- [ ] Test connection pooling
- [ ] Test connection failure handling
- [ ] Add timeout tests

# Task 14: test_api_endpoint_availability()
- [ ] Implement API endpoint test
- [ ] Mock API responses
- [ ] Test endpoint availability
- [ ] Test endpoint functionality
- [ ] Test endpoint security
- [ ] Add load tests

# Task 15: test_frontend_loading_success()
- [ ] Implement frontend loading test
- [ ] Mock frontend operations
- [ ] Test page loading
- [ ] Test component rendering
- [ ] Test user interactions
- [ ] Add accessibility tests
```

---

## üìù **DAILY DEVELOPMENT LOG TEMPLATE**

### **Date: [CURRENT_DATE]**
### **Phase: Week 1 - Script Testing Implementation**
### **Day: [DAY_NUMBER]**

#### **Tasks Completed:**
```bash
- [ ] Task 1: test_migration_script_execution()
- [ ] Task 2: test_backup_creation_success()
- [ ] Task 3: test_schema_updates_applied()
- [ ] Task 4: test_data_migration_complete()
- [ ] Task 5: test_fresh_data_collection()
```

#### **Progress Metrics:**
```bash
- Tests implemented: ___/15
- Tests passing: ___/15
- Test coverage: ___%
- Code quality: ___%
- Documentation: ___%
```

#### **Issues Encountered:**
```bash
- Issue 1: [DESCRIPTION] - [RESOLUTION]
- Issue 2: [DESCRIPTION] - [RESOLUTION]
- Issue 3: [DESCRIPTION] - [RESOLUTION]
```

#### **Next Steps:**
```bash
- [ ] Continue with remaining tasks
- [ ] Update documentation
- [ ] Run full test suite
- [ ] Prepare for next phase
```

#### **Notes:**
```bash
- [IMPORTANT_NOTES]
- [LEARNINGS]
- [IMPROVEMENTS]
```

---

## üéØ **SUCCESS CRITERIA**

### **Week 1 Success Criteria:**
- ‚úÖ **15 script tests implemented** and passing
- ‚úÖ **100% test coverage** for script functionality
- ‚úÖ **All acceptance criteria** met
- ‚úÖ **Documentation updated** and complete
- ‚úÖ **No regressions** introduced
- ‚úÖ **Ready for Week 2** implementation

### **Overall Success Criteria:**
- ‚úÖ **255+ tests implemented** and passing
- ‚úÖ **100% test coverage** across all components
- ‚úÖ **All acceptance criteria** met
- ‚úÖ **Production ready** system
- ‚úÖ **Comprehensive documentation** complete
- ‚úÖ **Zero critical issues** remaining

---

## üö® **EMERGENCY PROCEDURES**

### **If Confusion Occurs:**
1. **STOP** all current work
2. **REVIEW** this guidance document
3. **CHECK** current phase and task
4. **VALIDATE** against development plan
5. **RESUME** with clear focus

### **If Tests Fail:**
1. **ANALYZE** failure cause
2. **FIX** underlying issue
3. **RERUN** all tests
4. **VERIFY** no regressions
5. **DOCUMENT** the fix

### **If Progress Stalls:**
1. **IDENTIFY** blocker
2. **RESEARCH** solution
3. **IMPLEMENT** fix
4. **TEST** thoroughly
5. **CONTINUE** progress

---

**Status**: AI Agent Guidance System Complete - Ready for Implementation
